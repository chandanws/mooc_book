{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习基石 Assignment1 Q16-18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q16. First, we use an artificial data set to study `PLA`. The data set is in\n",
    "\n",
    "https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_math/hw1_15_train.dat\n",
    "\n",
    "Each line of the data set contains one ($x_n,y_n$) with $x_n\\in ℝ^4$. The first 4 numbers of the line contains the components of $x_n$ orderly, the last number is $y_n$.\n",
    "\n",
    "Please initialize your algorithm with $w=0$ and take sign(0) as −1.\n",
    "\n",
    "Implement a version of PLA by visiting examples in the naive cycle using the order of examples in the data set. Run the algorithm on the data set. What is the number of updates before the algorithm halts?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#line profiler\n",
    "%load_ext line_profiler \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt('hw1_15_train.dat',dtype=np.float32)\n",
    "(n, nx) = data.shape\n",
    "x = np.hstack((np.ones((n,1)), data[:,0:4])).T\n",
    "y = data[:,4].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.zeros((5,))\n",
    "\n",
    "def sign(w, x):\n",
    "    \"\"\"\n",
    "    Sign of w.T*x\n",
    "    \"\"\"\n",
    "    if np.dot(w.T, x)>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def check_error(w, x, i):\n",
    "    \"\"\"\n",
    "    check error sequentially from position i to find error\n",
    "    return index of x that causes error\n",
    "    \"\"\"\n",
    "    _,n = x.shape\n",
    "    for j in range(i+1, n):\n",
    "        if sign(w, x[:,j]) != y[j]:\n",
    "            return (True, j)\n",
    "    for j in range(i):\n",
    "        if sign(w, x[:,j]) != y[j]:\n",
    "            return (True, j)\n",
    "    return (False, 0)\n",
    "\n",
    "def pla(w, x, y):\n",
    "    \"\"\"\n",
    "    Perceptron Learning Algorithm(PLA)\n",
    "    Input: \n",
    "    w, size: nx, 1\n",
    "    x, size: nx, n\n",
    "    y, size: n, 1\n",
    "    \"\"\"\n",
    "    update_count = 0\n",
    "    error = check_error(w,x,0)\n",
    "    while error[0]: #while no error in PLA, stops\n",
    "        i = error[1] # get index\n",
    "        w = w + (y[i]*x[:,i])\n",
    "        error = check_error(w, x, i)\n",
    "        update_count += 1\n",
    "    return w, update_count\n",
    "\n",
    "\n",
    "w, update_count = pla(w, x, y)\n",
    "update_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q17. Implement a version of PLA by visiting examples in fixed, pre-determined random cycles throughout the algorithm. Run the algorithm on the data set. Please repeat your experiment for 2000 times, each with a different random seed. What is the average number of updates before the algorithm halts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.829\n"
     ]
    }
   ],
   "source": [
    "def find_a_mistake(w, x, i, visiting):\n",
    "    \"\"\"\n",
    "    check error sequentially from position i to find error\n",
    "    return index of x that causes error\n",
    "    \"\"\"\n",
    "    _, n = x.shape\n",
    "        \n",
    "    # visiting\n",
    "    for j in visiting[i:]:\n",
    "        if sign(w, x[:,j]) != y[j]:\n",
    "            return (True, j)\n",
    "    for j in visiting[:i]:\n",
    "        if sign(w, x[:,j]) != y[j]:\n",
    "            return (True, j)\n",
    "    return (False, 0)\n",
    "\n",
    "def random_pla(w, x, y, visiting):\n",
    "    \"\"\"\n",
    "    Perceptron Learning Algorithm(PLA)\n",
    "    Randomly visit input \n",
    "    Input: \n",
    "    w, size: nx, 1\n",
    "    x, size: nx, n\n",
    "    y, size: n, 1\n",
    "    \"\"\"\n",
    "    update_count = 0\n",
    "    error = find_a_mistake(w, x, 0, visiting)\n",
    "    while error[0]: #while no error in PLA, stops\n",
    "        i = error[1] # get index\n",
    "        w = w + (y[i]*x[:,i])\n",
    "        error = find_a_mistake(w, x, i, visiting)\n",
    "        update_count += 1\n",
    "    return w, update_count\n",
    "\n",
    "\n",
    "#visit 2000 times\n",
    "seed = 1; # set seed\n",
    "update_count_sum = 0\n",
    "for i in range(2000):\n",
    "    ##visiting\n",
    "    np.random.seed(seed)\n",
    "    visiting = np.arange(n)\n",
    "    np.random.shuffle(visiting)\n",
    "    \n",
    "    w = np.zeros((5,))\n",
    "    w, update_count = random_pla(w, x, y, visiting)\n",
    "    update_count_sum += update_count\n",
    "    seed += 1 # change seed to produce difference visiting\n",
    "    \n",
    "update_count = update_count_sum/2000\n",
    "print(update_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q18. Next, we play with the pocket algorithm. Modify your PLA in Question 16 to visit examples purely randomly, and then add the \"pocket\" steps to the algorithm. We will use\n",
    "\n",
    "https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_math/hw1_18_train.dat\n",
    "\n",
    "as the training data set $\\mathcal{D}$, and\n",
    "\n",
    "https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_math/hw1_18_test.dat\n",
    "\n",
    "as the test set for \"verifying'' the g returned by your algorithm (see lecture 4 about verifying). The sets are of the same format as the previous one. Run the pocket algorithm with a total of 50 updates on $\\mathcal{D}$ , and verify the performance of $w_{POCKET}$ using the test set. Please repeat your experiment for 2000 times, each with a different random seed. What is the average error rate on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## data preparation\n",
    "data = np.loadtxt('hw1_18_train.dat',dtype=np.float32)\n",
    "(n, nxy) = data.shape\n",
    "x = np.hstack((np.ones((n,1)), data[:,0:nxy-1])).T\n",
    "y = data[:,nxy-1].astype(int)\n",
    "\n",
    "## test data\n",
    "data_test = np.loadtxt('hw1_18_test.dat',dtype=np.float32)\n",
    "(ntest, nxytest) = data.shape\n",
    "xtest = np.hstack((np.ones((ntest,1)), data[:,0:nxytest-1])).T\n",
    "ytest = data[:,nxytest-1].astype(int)\n",
    "\n",
    "n, ntest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP=  0\n",
      "STEP=  10\n",
      "STEP=  20\n",
      "STEP=  30\n",
      "STEP=  40\n",
      "average error= 0.09884\n"
     ]
    }
   ],
   "source": [
    "def predict(w, x, y):\n",
    "    \"\"\"\n",
    "    Predicting error using vectorization\n",
    "    \"\"\"\n",
    "    error_vector = ((np.dot(w.T, x)>0) != (y==1))\n",
    "    return sum(error_vector)/x.shape[1]\n",
    "\n",
    "\n",
    "def pocket(w, x, y, visiting, learning_rate, update_count_limit, count_limit):\n",
    "    \"\"\"\n",
    "    Pocket Algorithm\n",
    "    Randomly visiting(set by seed)\n",
    "    Input: \n",
    "    w, size: nx, 1\n",
    "    x, size: nx, n\n",
    "    y, size: n, 1\n",
    "    \"\"\"\n",
    "    error_rate = 1\n",
    "    update_count = 0\n",
    "    error = find_a_mistake(w, x, 0, visiting)\n",
    "    count = 0\n",
    "    once_count = 0\n",
    "    #while no error in Pocket or after 50 updates, stops\n",
    "    # if count > n, all possible w are used.\n",
    "    while (error[0] and (update_count < update_count_limit) and (count < count_limit)): \n",
    "        i = error[1] # get index\n",
    "        w = w + learning_rate*(y[i]*x[:,i])\n",
    "        error_temp = predict(w, x, y)\n",
    "        if  error_temp < error_rate:\n",
    "            best_w = w\n",
    "            error_rate = error_temp \n",
    "            update_count += 1\n",
    "            once_count = 0\n",
    "        error = find_a_mistake(w, x, i, visiting)\n",
    "        count += 1\n",
    "        once_count += 1\n",
    "        if once_count > x.shape[1]:\n",
    "            return best_w\n",
    "    return best_w\n",
    "\n",
    "def model(x, y, xtest, ytest, N=2000, learning_rate=0.01,\n",
    "          update_count_limit=50, count_limit=float(\"inf\")):\n",
    "    \"\"\"\n",
    "    Pocket Model\n",
    "    \"\"\"\n",
    "    seed = 1; # set seed\n",
    "    error_rate = []; #error_rate\n",
    "    #visit N times\n",
    "    for i in range(N):\n",
    "        ##visiting\n",
    "        np.random.seed(seed)\n",
    "        visiting = np.arange(n)\n",
    "        np.random.shuffle(visiting)\n",
    "\n",
    "        w = np.zeros((5,))\n",
    "        w = pocket(w, x, y, visiting, learning_rate, update_count_limit, count_limit)\n",
    "        error_rate.append(predict(w, xtest, ytest))\n",
    "        seed += 1 # change seed to produce difference visiting\n",
    "        if (i%10 == 0):\n",
    "            print('STEP= ', i)\n",
    "    print(\"average error=\", np.average(error_rate))\n",
    "    \n",
    "model(x, y, xtest, ytest, N=50) #N=100 costs less than 1 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Modify your algorithm in Q18 to return $w_{50}$ instead of $\\hat{w}$ (the pocket vector) after 50 updates.\n",
    "\n",
    "Run the modified algorithm on $\\mathcal{D}$, and verify the performance using the test set.\n",
    "\n",
    "Please repeat your experiment for 2000 times, each with a different random seed. What is the average error rate on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP=  0\n",
      "STEP=  10\n",
      "STEP=  20\n",
      "STEP=  30\n",
      "STEP=  40\n",
      "average error= 0.124\n"
     ]
    }
   ],
   "source": [
    "#set update_count_limit > count_limit\n",
    "model(x, y, xtest, ytest, N=50, learning_rate=0.01, \n",
    "      update_count_limit=51, count_limit=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
